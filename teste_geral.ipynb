{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1c24a8ab-64d4-418a-ba4e-992dfb9af416",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nayra/.local/lib/python3.10/site-packages/sentence_transformers/cross_encoder/CrossEncoder.py:11: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
      "  from tqdm.autonotebook import tqdm, trange\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "from transformers import AutoTokenizer\n",
    "from PyPDF2 import PdfReader\n",
    "from transformers import pipeline\n",
    "\n",
    "import chromadb\n",
    "import torch\n",
    "import ollama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "eeeafb79-9ec3-4468-a3e1-a47f67646ac4",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = SentenceTransformer(\"sentence-transformers/all-MiniLM-L12-v2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ac2cb5a0-f1ce-42b2-b06c-a99feb643c94",
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = \"pdf/JavaBasico.pdf\"\n",
    "\n",
    "\n",
    "reader = PdfReader(PATH)\n",
    "\n",
    "text_load = ''.join(page.extract_text() for page in reader.pages)\n",
    "\n",
    "client = chromadb.PersistentClient(path=\"chromadb\")\n",
    "collection = client.get_or_create_collection(name=\"vector-langchain\")\n",
    "history_collection = client.get_or_create_collection(name=\"chat_history\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fc61b6c5-5b23-42be-98cb-903e3b08356d",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_split = []\n",
    "metadata=[]\n",
    "chunk_size = 1024\n",
    "chunk_overlap = 8\n",
    "\n",
    "for i in range(0, len(text_load), chunk_size):\n",
    "    start = i\n",
    "    end = i + chunk_size\n",
    "    if start != 0:\n",
    "        start = start - chunk_overlap\n",
    "        end =  end + chunk_overlap\n",
    "    text_split.append(text_load[start:end])\n",
    "    metadata.append({\"name\": \"book-langchain\", \"partition\": f\"{i}\"})\n",
    "embeddings_db = embeddings.encode(text_split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "47d40413-38e1-4084-bb0b-3f1e512d70d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, d in enumerate(text_split):\n",
    "\n",
    "      collection.add(\n",
    "              ids=[str(i)],\n",
    "              embeddings=embeddings_db[[i]],\n",
    "              documents=[d],\n",
    "              metadatas=metadata[i]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "eb0c7b37-9404-45bb-a0ed-7419c3593e2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Pergunte algo o que é python?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Entendi! Sem mais informações disponíveis, peço desculpas, mas não posso fornecer respostas precisas ou úteis neste momento. Como assistente de chatbot, tenho acesso limitado a informações e não posso garantir a precisão ou validade das informações fornecidas. Se você tiver alguma outra pergunta ou precisar de ajuda em algum assunto, estou á disposição para ajudá-lo.\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Pergunte algo o que é classe em orientação a objeto?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bem-vindo! Em relação às confusões sobre classes e objetos, é importante entender que uma classe representa um modelo ou protótipo de um objeto, enquanto os objetos são instâncias concretas dos modelos.\n",
      "\n",
      "Uma classe pode ser pensada como um plano de construção para um edifício, onde você tem todos os detalhes do projeto, desde a forma do prédio até as características de cada quarto. Já os objetos são as instâncias concretas desse edifício, com suas próprias características únicas.\n",
      "\n",
      "No mundo real, você teria uma classe \"Carro\", que representa o modelo de um carro. Cada carro é um objeto instanciado da classe \"Carro\", com características específicas, como cor, modelo, combustível, etc.\n",
      "\n",
      "Nosso sistema de negócios utiliza a mesma abordagem. Temos classes que representam os objetos de negócio, e cada objeto é uma instância concreta dessa classe, com características únicas. Por exemplo, temos uma classe \"Aluno\", que representa o modelo de um aluno do sistema. Cada aluno é um objeto instanciado da classe \"Aluno\", com características específicas, como nome, endereço, idade, notas, etc.\n",
      "\n",
      "Para evitar confusões, é importante entender que uma classe é um modelo ou protótipo de um objeto, enquanto os objetos são instâncias concretas desses modelos. Além disso, é fundamental usar atributos e métodos para dar características únicas aos objetos instanciados das classes.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "Interrupted by user",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[17], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m      3\u001b[0m     chat_history \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m----> 4\u001b[0m     prompt \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43minput\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mPergunte algo\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      5\u001b[0m     response \u001b[38;5;241m=\u001b[39m embeddings\u001b[38;5;241m.\u001b[39mencode([prompt])\n\u001b[1;32m      6\u001b[0m     results \u001b[38;5;241m=\u001b[39m collection\u001b[38;5;241m.\u001b[39mquery(\n\u001b[1;32m      7\u001b[0m             query_embeddings\u001b[38;5;241m=\u001b[39mresponse,\n\u001b[1;32m      8\u001b[0m             n_results\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m,\n\u001b[1;32m      9\u001b[0m             where\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mname\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbook-langchain\u001b[39m\u001b[38;5;124m\"\u001b[39m}\n\u001b[1;32m     10\u001b[0m         )\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/ipykernel/kernelbase.py:1282\u001b[0m, in \u001b[0;36mKernel.raw_input\u001b[0;34m(self, prompt)\u001b[0m\n\u001b[1;32m   1280\u001b[0m     msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mraw_input was called, but this frontend does not support input requests.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1281\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m StdinNotImplementedError(msg)\n\u001b[0;32m-> 1282\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_input_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1283\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1284\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_parent_ident\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mshell\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1285\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_parent\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mshell\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1286\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpassword\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   1287\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/ipykernel/kernelbase.py:1325\u001b[0m, in \u001b[0;36mKernel._input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m   1322\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m:\n\u001b[1;32m   1323\u001b[0m     \u001b[38;5;66;03m# re-raise KeyboardInterrupt, to truncate traceback\u001b[39;00m\n\u001b[1;32m   1324\u001b[0m     msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInterrupted by user\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m-> 1325\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m(msg) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1326\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[1;32m   1327\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlog\u001b[38;5;241m.\u001b[39mwarning(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInvalid Message:\u001b[39m\u001b[38;5;124m\"\u001b[39m, exc_info\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: Interrupted by user"
     ]
    }
   ],
   "source": [
    "while True:\n",
    "\n",
    "    chat_history = []\n",
    "    prompt = input(\"Pergunte algo\")\n",
    "    response = embeddings.encode([prompt])\n",
    "    results = collection.query(\n",
    "            query_embeddings=response,\n",
    "            n_results=2,\n",
    "            where={\"name\": \"book-langchain\"}\n",
    "        )\n",
    "\n",
    "    data = results['documents'][0]\n",
    "    distance = results['distances']\n",
    "    \n",
    "    for k in range(2):\n",
    "    \n",
    "        if distance[0][k] > 0.9:\n",
    "            data = \"Você é um assistente de chatbot e tem acesso limitado a informações. Nesse caso, diga que não tem conhecimento acerca da pergunta.\"\n",
    "    \n",
    "    output = ollama.generate(\n",
    "            model=\"llama2\",\n",
    "            prompt=f\"Você é um chatbot assistente. Com base no histórico de conversa: {chat_history}. Responda em português baseado somente na seguinte informação: {data}\"\n",
    "            )\n",
    "    \n",
    "    output = output['response']\n",
    "    print(output)\n",
    "\n",
    "    chat_history.append(f\"Human: {prompt}\\nAi: {output}\")\n",
    "    # embeddings_history = embeddings.encode(chat_history)\n",
    "\n",
    "    # history_collection.add(\n",
    "    #             ids=[str(i)],\n",
    "    #             embeddings=embeddings_history[[i]],\n",
    "    #             documents=[chat_history]\n",
    "    # )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "534c8f95-efa0-4f15-8c5b-9128d3c00253",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
