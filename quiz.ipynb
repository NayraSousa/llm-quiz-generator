{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5c437a34-1e87-44fa-ad72-a866197ba80e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nayra/.local/lib/python3.10/site-packages/sentence_transformers/cross_encoder/CrossEncoder.py:11: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
      "  from tqdm.autonotebook import tqdm, trange\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "from transformers import AutoTokenizer\n",
    "from PyPDF2 import PdfReader\n",
    "from transformers import pipeline\n",
    "\n",
    "import chromadb\n",
    "import torch\n",
    "import ollama\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3495e56c-8bf2-47c2-8f0b-5ea9c3a98ec9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "client = chromadb.PersistentClient(path=\"chromadb\")\n",
    "collection = client.get_or_create_collection(name=\"vector-langchain\")\n",
    "history_collection = client.get_or_create_collection(name=\"chat_history\")\n",
    "embeddings = SentenceTransformer(\"sentence-transformers/all-MiniLM-L12-v2\")\n",
    "\n",
    "dir = \"pdf/\"\n",
    "metadatas = []\n",
    "chunks = []  \n",
    "chunk_size = 432\n",
    "chunk_overlap = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "84863fb7-78e3-4472-a361-1f140e59aea9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Livro de Arquitetura e organização de computadores.pdf\n",
      "Learning LangChain-O'Reilly Media (2024).pdf\n",
      "JavaBasico.pdf\n"
     ]
    }
   ],
   "source": [
    "for arq in os.listdir(dir):\n",
    "    \n",
    "    start_index = 0\n",
    "    text_join = \"\"\n",
    "    \n",
    "    metadatas.append({\"name\": arq})\n",
    "    print(arq)\n",
    "    text = PdfReader(dir+arq)\n",
    "    text_join = ''.join(page.extract_text() for page in text.pages)\n",
    "\n",
    "    for i in range(0, len(text_join), chunk_size):\n",
    "        start = i\n",
    "        end = i + chunk_size\n",
    "        if start != 0:\n",
    "            start = start - chunk_overlap\n",
    "            end =  end + chunk_overlap\n",
    "        chunks.append(text_join[start:end])\n",
    "        metadatas.append({\"name\": arq, \"page\": i})\n",
    "\n",
    "embeddings_db = embeddings.encode(chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fa624eb4-c20d-489b-bb07-96176cbbc745",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, d in enumerate(chunks):\n",
    "\n",
    "      collection.add(\n",
    "              ids=[str(i)],\n",
    "              embeddings=embeddings_db[[i]],\n",
    "              documents=[d],\n",
    "              metadatas=metadatas[i]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0110b947-0c15-4b88-893c-ffb156436c72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Pergunte algo memória ram\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.5562481880187988, 0.6207898855209351, 0.6782195568084717, 0.6851325631141663, 0.7022801637649536, 0.7119332551956177, 0.7519334554672241, 0.7666471004486084, 0.7671561241149902, 0.7728975415229797]]\n",
      "['RAM) é uma forma de memória de acesso aleatório usada para a memória cache; veja o Capítulo 5.\\n15 A memória flash consiste em uma forma versátil de memória usada tanto por microcontroladores como por memória externa; esse assunto é discutido no Capítulo 6.\\nBOKK_STALLINGS.indb   31 01/09/17   09:15Arquitetura e organização de computadores32\\n}}Gerenciamento de energia: administra os vários modos de operação do processador e de periféricos em \\nbai', '8\\nRAM não volátil dentro da hierarquia da memória.\\nSRAM\\nSTT-RAM\\nPCRAM\\nReRAMDesempenho\\ne durabilidade\\naumentados\\nCusto decrescente\\npor bit, capacidade\\nou densidade crescentesDRAM\\nFLASH NAND \\nDISCO RÍGIDO \\nBOKK_STALLINGS.indb   156 01/09/17   09:15Capítulo 5 } Memória interna  \\n157\\nAo longo do tempo, cada uma dessas tecnologias tem visto melhorias em escala: densidade de bit mais alta, \\nvelocidade mais alta, menor consumo de energia e menor custo', 'sso aleatório. Uma característica distinta da memória que é designada como RAM é a possibilidade tanto de ler dados como escrever novos dados na memória de um modo fácil e rápido. Tanto a leitura como a escrita são realizadas por meio de sinais elétricos.\\nBOKK_STALLINGS.indb   138 01/09/17   09:15Capítulo 5 } Memória interna  \\n139\\nTabela 5.1\\nTipos de memória semicondutora.\\nTipo de memória Categoria ApagamentoMecanismo de \\ngravação Volatilidade\\n', 'ão Volatilidade\\nMemória de acesso \\naleatório (RAM)Memória de \\nleitura-gravaçãoEletricamente, em \\nnível de byteEletricamente Volátil\\nMemória somente de leitura (ROM) Memória \\nsomente \\nde leituraNão é possívelMáscaras\\nNão volátilROM programável (PROM —  \\ndo inglês, Programmable ROM)\\nEletricamentePROM apagável (EPROM — do inglês, Erasable PROM)\\nMemória \\nprincipalmente \\nde leituraLuz UV, Em nível \\nde chip\\nPROM eletricamente apagável (EEPROM — do in', 'clui o processador Cortex-M3, memória RAM estática (SRAM) de dados,14 \\ne memória flash15 para armazenar instruções de programa e dados de aplicação não variáveis. A memória \\nflash é não volátil (os dados não são perdidos quando a energia é desligada), sendo, então, ideal para esse propósito. A SRAM armazena dados variáveis. Essa área inclui uma interface de depuração, que torna fácil reprogramar e atualizar o sistema no campo.\\n}}Portas paralela', '57\\nCódigo de Hamming, 146 Memória não volátil, 140 RAM resistiva (ReRAM), 157\\nDRAM de taxa dupla de dados (DDR-DRAM), 152Memória principalmente de leitura, 141ROM programável e apagável (EPROM), 141\\nDRAM síncrona (SDRAM), 150 Memória semicondutora, 138ROM programável eletricamente apagável (EEPROM), 141\\nErro não permanente, 145 Memória somente de leitura (ROM), 140 ROM programável (PROM), 141\\nFalha permanente, 145 Memória volátil, 139 Síndroma,', 'ão geral do sistema de memória do ARM.\\nHard ware\\nde contr ole\\nde acessoBits de acesso,\\ndomínio\\nBits de acesso,\\ndomínio\\nAbortar\\nBits de\\ncontr oleEnder eço f ísicoEnder eço\\nfísico\\nEnder eço\\nfísico\\nEnder eço\\nvirtualEnder eço virtual\\nCore\\ndo ARMTLBUnidade de ger enciamento de memória (MMU)\\nHard ware \\nde bu sca de \\nlinha de cacheHard ware  de\\ntradução da\\nmemória\\nvirtual\\nMemória\\nprincipal\\nCache e\\nbuffer de\\ngravação\\nBOKK_STALLINGS.indb   262 01/09/17 ', '(PCRAM) e a RAM resistiva (ReRAM) (THE INTERNATIONAL..., 2014, GOERING, 2012). Todas elas são para produção em volume. Contudo, como a flash NAND e algumas extensões de flash NOR estão ainda dominando as aplicações, essas memórias emer -\\ngentes têm sido usadas em aplicações especiais e ainda não cumpriram sua promessa original de se tornarem a tendência dominante em memória não volátil de alta densidade. É provável que isso mude nos próximos an', ' tratadas as três novas e importantes tecnologias RAM em estado sólido não volátil que ocupam diferentes posições na hierarquia da memória: STT-RAM, \\nPCRAM e ReRAM.\\n}}Acesso direto à cache (DCA — do inglês, Direct Cache Access): para atender às demandas de processa-\\nmento de protocolos para conexões de rede de alta velocidade, a Intel e outros fabricantes desenvolve-ram tecnologias DCA que proporcionam uma taxa de transferência muito maior do q', ' (EEPROM — do inglês, \\nElectrically Erasable PROM)Eletricamente, \\nem nível de byte\\nMemória flashEletricamente, \\nem nível de bloco\\nOutra característica distinta da RAM é que ela é volátil. Uma RAM deve receber uma fonte de alimen-\\ntação constante. Se a energia for interrompida, os dados são perdidos. Assim, a RAM só pode ser usada como \\narmazenamento temporário. As duas formas tradicionais de RAM usadas nos computadores são DRAM e SRAM. As mais ']\n",
      "\n",
      "\n",
      "**1. Qual o propósito principal da memória RAM?**\n",
      "\n",
      "A) Armazenar instruções de programa.\n",
      "B) Armazenar dados variáveis.\n",
      "C) Administrar o consumo de energia.\n",
      "D) Armazenar dados não voláteis.\n",
      "\n",
      "**Resposta correta:** B) Armazenar dados variáveis.\n",
      "\n",
      "**Explicação:** A memória RAM é usada para armazenar dados dinâmicos que precisam ser acessados rapidamente durante o funcionamento do computador.\n",
      "\n",
      "\n",
      "**2. Qual tipo de memória não é volátil?**\n",
      "\n",
      "A) RAM\n",
      "B) Flash\n",
      "C) ROM\n",
      "D) SDRAM\n",
      "\n",
      "**Resposta correta:** C) ROM\n",
      "\n",
      "**Explicação:** A memória ROM não é volátil, o que significa que os dados são preservados mesmo quando a alimentação é desligada.\n",
      "\n",
      "\n",
      "**3. Qual o mecanismo de gravação da memória Flash?**\n",
      "\n",
      "A) Eletricamente\n",
      "B) Mecanicamente\n",
      "C) Termicamente\n",
      "D) Ópticamente\n",
      "\n",
      "**Resposta correta:** A) Eletricamente\n",
      "\n",
      "**Explicação:** A memória Flash usa o armazenamento elétrico para gravar dados.\n",
      "\n",
      "\n",
      "**4. Qual o tipo de memória mais rápido?**\n",
      "\n",
      "A) RAM\n",
      "B) Flash\n",
      "C) ROM\n",
      "D) SDRAM\n",
      "\n",
      "**Resposta correta:** A) RAM\n",
      "\n",
      "**Explicação:** A memória RAM é o tipo de memória mais rápido, com tempos de acesso menores.\n",
      "\n",
      "\n",
      "**5. Qual o uso principal da memória Flash?**\n",
      "\n",
      "A) Armazenamento de instruções de programa\n",
      "B) Armazenamento de dados de aplicação\n",
      "C) Administração do consumo de energia\n",
      "D) Armazenamento de dados volumosos\n",
      "\n",
      "**Resposta correta:** A) Armazenamento de instruções de programa\n",
      "\n",
      "**Explicação:** A memória Flash é usada para armazenar instruções de programa e dados de aplicação não variáveis.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Pergunte algo langchain\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.708989679813385, 0.785416305065155, 0.8077477216720581, 0.8599618673324585, 0.8600448369979858, 0.867042064666748, 0.8695042729377747, 0.8980491161346436, 0.9132727384567261, 0.9156815409660339]]\n",
      "[' for sharing with\\nteammates.\\nLangChain contains many integrations with third-party\\nservices (like Google Sheets, W olfram Alpha, Zapier , just to\\nname a few) exposed as tools , which is a standard interface\\nfor functions to be used in the tool-calling technique.\\nFor RAG , LangChain provides integrations with the major\\nembedding models  (language models designed to output a\\nnumeric representation, the embedding , of the meaning ofa sentence, par', 'nally , LangChain provides the tools to compose these\\nbuilding blocks into cohesive applications. Chapters 1\\nthrough 6 talk more about this.In addition to this library , LangChain provides LangSmith , a\\nplatform to help debug, test, deploy , and monitor AI\\nworkﬂows, and LangServe , a platform that makes it easier\\nto deploy a LangChain-powered API. W e cover these in\\nchapters 7 and 8.\\nWhat to Expect from This Book\\nWith this book we hope to conve', ' deﬁnitions of these concepts very shortly .\\nNOTE\\nBuilding LLM applications with or without LangChain requires the use\\nof an LLM (read on for explanations for all these concepts). In this book\\nwe’ll be making use of the OpenAI API, whose pricing can be found\\nhere, as the LLM provider we use in the code examples. One of the\\nbeneﬁts of working with LangChain (more on this later) is you can\\nfollow all along all of these examples using either OpenA', 'ut if you try to\\nuse both models in the same conversation you’ll\\nimmediately run into issues, as their chat message formats\\nare subtly incompatible. LangChain abstracts away these\\ndiﬀerences to enable building applications that are truly\\nindependent of a particular provider . For instance, with\\nLangChain a chatbot conversation where you use both\\nOpenAI and Anthropic models just works.Finally , as you build out your LLM applications with several', ' being locked-in to a single\\nprovider . We’ll use these in Chapter 1.\\nLangChain also provides prompt template  abstractions,\\nwhich enable you to reuse prompts more than once,\\nseparating what’s static text in the prompt from\\nplaceholders that will be diﬀerent for each time you send it\\nto the LLM to get a completion generated. W e’ll talk more\\nabout these also in Chapter 1. LangChain prompts can also\\nbe stored in the LangChain Hub for sharing wit', 'ons with several\\nof these components we’ve found it useful to have the\\norchestration  capabilities of LangChain:\\nAll major components are instrumented by the callbacks\\nsystem for observability (more on this in Chapter 8).\\nAll major components implement the same interface\\n(more on this towards the end of this chapter).\\nLong-running LLM applications can be interrupted,\\nresumed, or retried (more on this in Chapter 6).\\nGetting Set Up with LangChain', 'Learning LangChain\\nBuild an AI Chatbot Trained on Y our Data\\nWith Early Release ebooks, you get books in their earliest\\nform—the authors’ raw and unedited content as they write\\n—so you can take advantage of these technologies long\\nbefore the oﬀicial release of these titles.\\nMayo Oshin and Nuno Campos\\nLearning LangChain\\nby Mayo Oshin  and Nuno Campos\\nCopyright © 2025 Olumayowa Olufemi Oshin. All rights\\nreserved.\\nPrinted in the Un', 'primer on why we think it useful to use\\nLangChain to build LLM applications.WHY LANGCHAIN?\\nYou can of course build LLM applications without\\nLangChain. The most obvious alternative is to use the SDK\\n—the software package exposing the methods of their\\nHTTP API as functions in the programming language of\\nyour choice—of the LLM provider you tried ﬁrst, for\\nexample, OpenAI. W e think learning LangChain will pay oﬀ\\nin the short term and over the long', \"ssagefrom langchain_core.messages import HumanMessage  \\nmodel = ChatOpenAI()  \\nprompt = [HumanMessage('What is the capital of Fr\\ncompletion = model.invoke(prompt)\\nimport {ChatOpenAI} from '@langchain/openai'  \\nimport {HumanMessage} from '@langchain/core/messa\\nconst model = new ChatOpenAI()  \\nconst prompt = [new HumanMessage('What is the cap\\nconst completion = await model.invoke(prompt)  \\ncompletion\\nAIMessage(content='The capital of France is Pa\", 'r the results out of\\nthe box are good enough for your use case. If not,\\nthen look at the other half of the LangChain libraries:\\nInterchangeable building blocks\\nComponents that can be easily swapped out for\\nalternatives. Every component (an LLM, chat model,output parser , and so on—more on these shortly)\\nfollows a shared speciﬁcation, which makes your\\napplication future-proof . As new capabilities are\\nreleased by model providers, and as your nee']\n",
      "\n",
      "\n",
      "**1. Qual o objetivo principal dos integrações do LangChain?**\n",
      "\n",
      "A) Compartilhar dados com colegas de trabalho.\n",
      "B) Expor ferramentas padronizadas.\n",
      "C) Chamar funções de serviços externos.\n",
      "D) Gerar modelos de linguagem.\n",
      "\n",
      "**Resposta correta:** B\n",
      "\n",
      "**Explicação:** Os integrações do LangChain fornecem uma interface padrão para funções que podem ser usadas na técnica de chamada de ferramentas.\n",
      "\n",
      "\n",
      "**2. Quais são alguns serviços externos integrados ao LangChain?**\n",
      "\n",
      "A) Google Sheets, Wolfram Alpha e Zapier.\n",
      "B) Facebook, Twitter e Instagram.\n",
      "C) Spotify, Netflix e YouTube.\n",
      "D) Gmail, Drive e Docs.\n",
      "\n",
      "**Resposta correta:** A\n",
      "\n",
      "**Explicação:** O LangChain oferece integrações com vários serviços externos, incluindo Google Sheets, Wolfram Alpha e Zapier.\n",
      "\n",
      "\n",
      "**3. Qual é o propósito dos modelos de embeddings do LangChain?**\n",
      "\n",
      "A) Gerar representações numéricas do significado de frases.\n",
      "B) Traduzir textos de um idioma para outro.\n",
      "C) Classificar textos em diferentes categorias.\n",
      "D) Compartilhar dados de equipe.\n",
      "\n",
      "**Resposta correta:** A\n",
      "\n",
      "**Explicação:** Os modelos de embeddings são modelos de linguagem projetados para gerar uma representação numérica do significado de uma frase.\n",
      "\n",
      "\n",
      "**4. Qual técnica é usada para usar as integrações do LangChain?**\n",
      "\n",
      "A) Chamada de funções.\n",
      "B) API.\n",
      "C) Webhook.\n",
      "D) Socket.\n",
      "\n",
      "**Resposta correta:** A\n",
      "\n",
      "**Explicação:** A técnica de chamada de ferramentas usa a chamada de funções para usar as integrações do LangChain.\n",
      "\n",
      "\n",
      "**5. Qual é o objetivo principal do uso de integrações de modelo de embeddings no LangChain?**\n",
      "\n",
      "A) Melhorar a inteligência dos modelos.\n",
      "B) Reduzir o tamanho dos modelos.\n",
      "C) Aumentar o desempenho dos modelos.\n",
      "D) Simplificar o uso dos modelos.\n",
      "\n",
      "**Resposta correta:** C\n",
      "\n",
      "**Explicação:** O uso de integrações de modelo de embedding no LangChain aumenta o desempenho dos modelos.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "while True:\n",
    "\n",
    "    query = []\n",
    "\n",
    "    prompt = input(\"Pergunte algo\")\n",
    "    response = embeddings.encode([prompt])\n",
    "    results = collection.query(\n",
    "            query_embeddings=response,\n",
    "            n_results=10,\n",
    "        )\n",
    "\n",
    "    metadata = results['metadatas'][0]\n",
    "    data = results['documents'][0]\n",
    "    distance = results['distances'] \n",
    "    \n",
    "    print(distance)\n",
    "    print(data)\n",
    "          \n",
    "    for k in range(10):\n",
    "        if distance[0][k] < 0.74:\n",
    "            query.append(data[k])\n",
    "\n",
    "    prompt_template = f\"\"\"You are a chatbot specialized in generating quizzes. \n",
    "                        Generate a quiz with 5 questions in Portuguese in the following context: {query} with the following format: question, options and explanation of the right answer\"\"\"\n",
    "\n",
    "    if len(query) == 0:\n",
    "            prompt_template = \"Você é um assistente de chatbot e tem acesso limitado a informações. Nesse caso, diga que não tem conhecimento acerca da pergunta.\"\n",
    "    \n",
    "    output = ollama.generate(\n",
    "            model=\"gemma\",\n",
    "            prompt=prompt_template\n",
    "            )\n",
    "    print(\"\\n\")\n",
    "    output = output['response']\n",
    "    print(output)\n",
    "    print(\"\\n\")\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
