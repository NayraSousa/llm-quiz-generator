{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PyPDF2 import PdfReader\n",
    "import chromadb\n",
    "PATH = \"pdf/Learning LangChain-O'Reilly Media (2024).pdf\"\n",
    "\n",
    "\n",
    "reader = PdfReader(PATH)\n",
    "        \n",
    "text_load = ''.join(page.extract_text() for page in reader.pages)\n",
    "\n",
    "client = chromadb.PersistentClient(path=\"chromadb\")\n",
    "collection = client.get_or_create_collection(name=\"vector-langchain\") \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_split = []\n",
    "metadata=[]\n",
    "chunk_size = 512\n",
    "chunk_overlap = 8\n",
    "        \n",
    "for i in range(0, len(text_load), chunk_size):\n",
    "    start = i\n",
    "    end = i + chunk_size\n",
    "    if start != 0:\n",
    "        start = start - chunk_overlap\n",
    "        end =  end + chunk_overlap\n",
    "    text_split.append(text_load[start:end])\n",
    "    metadata.append({\"name\": \"book-langchain\", \"partition\": f\"{i}\"})\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ollama\n",
    "\n",
    "for i, d in enumerate(text_split):\n",
    "        response = ollama.embeddings(model=\"mxbai-embed-large\",\n",
    "                                       prompt=d)\n",
    "        \n",
    "        collection.add(\n",
    "                ids=[str(i)],\n",
    "                embeddings=response['embedding'],\n",
    "                documents=[d],\n",
    "                metadatas=metadata[i]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "233.73208618164062\n",
      "[[' APIkey, and save it—you’ll need it soon.\\nNOTE\\nIn this book we’ll show code examples in both Python and JavaScript,\\nLangChain oﬀers the same functionality in both languages, so just pick\\none of them and follow the respective code snippets throughout the\\nbook. The code examples for each language will be equivalent between\\nthe two, so just pick whichever language you’re most comfortable with.\\nFirst, some setup instructions for readers using Python:\\n1. Ensure you have Python installed. See instructions here\\nfor your operating', 'hain_text_splitters import (  \\n    Language,  \\n    RecursiveCharacterTextSplitter,  \\n) And in JS:PYTHON_CODE = \"\"\"  \\ndef hello_world():  \\n    print(\"Hello, World!\")  \\n# Call the function  \\nhello_world()  \\n\"\"\" \\npython_splitter = RecursiveCharacterTextSplitter\\n    language=Language.PYTHON, chunk_size=50, chun\\n) \\npython_docs = python_splitter.create_documents([P\\n \\nimport { RecursiveCharacterTextSplitter } from \"@\\nconst PYTHON_CODE = `  \\ndef hello_world():  \\n    print(\"Hello, World!\")  \\n# Call the function  \\nhello_world()  \\n`;', 'llo_world()  \\n`; \\nconst pythonSplitter = RecursiveCharacterTextSpli\\n  chunkSize: 50,  \\n  chunkOverlap: 0,  \\n}); \\nconst pythonDocs = await pythonSplitter.createDocAnd the output:\\nNotice how we’re still using\\nRecursiveCharacterTextSplitter  as above, but now\\nwe’re creating an instance of it for a speciﬁc language,\\nusing the from_language  method. This one accepts the\\nname of the language, and the usual parameters for chunk\\nsize, and so on. Also notice we are now using the method\\ncreate_documents , which accepts a list of str']]\n"
     ]
    }
   ],
   "source": [
    "prompt = \"what is python?\"\n",
    "\n",
    "response = ollama.embeddings(\n",
    "    prompt=prompt,\n",
    "    model=\"mxbai-embed-large\"\n",
    "    )\n",
    "\n",
    "results = collection.query(\n",
    "    query_embeddings=[response[\"embedding\"]],\n",
    "    n_results=3,\n",
    "    where={\"name\": \"book-langchain\"}\n",
    "    )\n",
    "    \n",
    "distance = results['distances'][0][0]\n",
    "print(distance)\n",
    "\n",
    "data = results['documents']\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Olá! Em Portuguese, \"Python\" é um linguagem de programação popular e amplamente utilizada para desenvolver aplicativos desktop, web e móveis. Ela é conhecida por sua sintaxe clara e fácil de aprender, além de sua vastidiade de bibliotecas e recursos disponíveis para ajudar no desenvolvimento de aplicativos.\n",
      "\n",
      "Se você está procurando saber mais sobre a linguagem Python, pode consultar documentaçãooficial ou usar recursos on-line para aprender e entender melhor sua sintaxe e funcionalidades.\n"
     ]
    }
   ],
   "source": [
    "output = ollama.generate(\n",
    "        model=\"llama2\",\n",
    "        prompt=f\"You are a chatbot assistant that responds in Portuguese. Using this data: {data}. Respond to this prompt: {prompt}. If the {distance} is more than 200, say you don't know the answer\"\n",
    "    )\n",
    "\n",
    "print(output['response'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
